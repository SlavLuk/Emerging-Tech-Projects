{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Slav\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Adapted from : https://medium.com/@mannasiladittya/converting-mnist-data-in-idx-format-to-python-numpy-array-5cb9126f99f1\n",
    "\n",
    "\n",
    "#import required libraries\n",
    "\n",
    "import struct as st #This module performs conversions between Python values and C structs represented as Python bytes objects.\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Open the IDX file in readable binary mode.\n",
    "filename = {'train_images' : 'train-images.idx3-ubyte' ,'train_labels' : 'train-labels.idx1-ubyte',\n",
    "            'test_img':'t10k-images.idx3-ubyte','test_lbl':'t10k-labels.idx1-ubyte'}\n",
    "train_imagesfile = open(filename['train_images'],'rb')\n",
    "train_labelsfile = open(filename['train_labels'],'rb')\n",
    "test_imagesfile = open(filename['test_img'],'rb')\n",
    "test_labelsfile = open(filename['test_lbl'],'rb')\n",
    "\n",
    "\n",
    "# Set pointer to the beginning of the file.\n",
    "train_imagesfile.seek(0)\n",
    "train_labelsfile.seek(0)\n",
    "test_imagesfile.seek(0)\n",
    "test_labelsfile.seek(0)\n",
    "\n",
    "# Read the magic number\n",
    "magic_img = st.unpack('>4B',train_imagesfile.read(4))\n",
    "magic_lab = st.unpack('>4B',train_labelsfile.read(4))\n",
    "magic_test_img = st.unpack('>4B',test_imagesfile.read(4))\n",
    "magic_test_lab = st.unpack('>4B',test_labelsfile.read(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the dimensions of the Image data-set\n",
    "train_images = st.unpack('>I',train_imagesfile.read(4))[0] #num of images\n",
    "n_row_i = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n",
    "n_col_i = st.unpack('>I',train_imagesfile.read(4))[0] #num of column\n",
    "\n",
    "test_images = st.unpack('>I',test_imagesfile.read(4))[0] #num of images\n",
    "n_row_test = st.unpack('>I',test_imagesfile.read(4))[0] #num of rows\n",
    "n_col_test = st.unpack('>I',test_imagesfile.read(4))[0] #num of column\n",
    "\n",
    "# Read the dimensions of the Label data-set\n",
    "train_labels = st.unpack('>I',train_labelsfile.read(4))[0] #num of items\n",
    "test_labels = st.unpack('>I',test_labelsfile.read(4))[0] #num of items\n",
    "\n",
    "# Reading the Image data\n",
    "train_bytes_total = train_images*n_row_i*n_col_i*1 \n",
    "test_bytes_total = test_images*n_row_test*n_col_test*1 \n",
    "\n",
    "# 'B' is used since it is of 'unsigned char' C type and ‘integer’ Python type\n",
    "# and has standard size 1 as mentioned in the official documentation of struct.\n",
    "# ‘>’ is used since the data is in MSB first (high endian) format used by most \n",
    "# non-Intel processors, as mentioned in their original website.\n",
    "train_img = 255 - np.asarray(st.unpack('>'+'B'*train_bytes_total,train_imagesfile.read(train_bytes_total))).reshape((train_images,n_row_i,n_col_i))\n",
    "test_img =   255 - np.asarray(st.unpack('>'+'B'*test_bytes_total,test_imagesfile.read(test_bytes_total))).reshape((test_images,n_row_test,n_col_test))\n",
    " \n",
    "# Reading the label data\n",
    "train_lbl = np.asarray(st.unpack('>'+'B'*train_labels,train_labelsfile.read(train_labels))).reshape((train_labels))\n",
    "test_lbl = np.asarray(st.unpack('>'+'B'*test_labels,test_labelsfile.read(test_labels))).reshape((test_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to the expected CNN format \n",
    "train_img = train_img.reshape(train_img.shape[0], train_img.shape[1], train_img.shape[2], 1).astype('float32')\n",
    "test_img = test_img.reshape(test_img.shape[0], test_img.shape[1], test_img.shape[2], 1).astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img[122].reshape(28, 28), cmap='gray')\n",
    "print(test_lbl[122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode images_array & test_img\n",
    "train_img/=255\n",
    "test_img/=255\n",
    "\n",
    "# one hot encode\n",
    "train_lbl = kr.utils.to_categorical(train_lbl, 10)\n",
    "test_lbl = kr.utils.to_categorical(test_lbl, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 54s 897us/step - loss: 0.5022 - acc: 0.8695 - val_loss: 0.1710 - val_acc: 0.9507\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1515 - acc: 0.9564 - val_loss: 0.1112 - val_acc: 0.9683\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1047 - acc: 0.9698 - val_loss: 0.0863 - val_acc: 0.9742\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 56s 936us/step - loss: 0.0801 - acc: 0.9772 - val_loss: 0.0783 - val_acc: 0.9763\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 56s 925us/step - loss: 0.0663 - acc: 0.9810 - val_loss: 0.0608 - val_acc: 0.9816\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 57s 942us/step - loss: 0.0557 - acc: 0.9838 - val_loss: 0.0551 - val_acc: 0.9818\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 53s 890us/step - loss: 0.0478 - acc: 0.9864 - val_loss: 0.0511 - val_acc: 0.9829\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 55s 911us/step - loss: 0.0422 - acc: 0.9875 - val_loss: 0.0560 - val_acc: 0.9803\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0367 - acc: 0.9891 - val_loss: 0.0502 - val_acc: 0.9832\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 58s 975us/step - loss: 0.0326 - acc: 0.9905 - val_loss: 0.0505 - val_acc: 0.9832\n",
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.05049631343162619, 0.9832]\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# Convolution layer\n",
    "model.add(Conv2D(32,(3,3),input_shape = (train_img.shape[1],train_img.shape[2],1),activation = 'relu'))\n",
    "# Pooling as reducing feature map\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Full connection\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "\n",
    "# Compiling of the Model\n",
    "model.compile( optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit(train_img, train_lbl, validation_data=(test_img, test_lbl), epochs=10, batch_size=200)\n",
    "\n",
    "# Evaluation of the model\n",
    "metrics = model.evaluate(test_img, test_lbl, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5') \n",
    "\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0385329e-11 3.8763637e-10 3.4027703e-09 8.1594291e-05 6.4185306e-06\n",
      "  9.3264717e-08 4.7872064e-11 2.8813672e-06 7.8361001e-05 9.9983060e-01]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fffb283a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_model = model.predict(test_img[1005:1006])\n",
    " \n",
    "print(pred_model)\n",
    "\n",
    "print(test_lbl[1005])\n",
    "                \n",
    "plt.imshow(test_img[1005].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h5json' has no attribute 'h5tojson'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9dada7dcc162>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mh5json\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5_conv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh5tojson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"model_j.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'h5json' has no attribute 'h5tojson'"
     ]
    }
   ],
   "source": [
    "import h5json as h5_conv\n",
    "\n",
    "md = h5_conv.h5tojson(model,\"model_j.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
