{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from : https://medium.com/@mannasiladittya/converting-mnist-data-in-idx-format-to-python-numpy-array-5cb9126f99f1\n",
    "\n",
    "\n",
    "#import required libraries\n",
    "\n",
    "import struct as st #This module performs conversions between Python values and C structs represented as Python bytes objects.\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as kr\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Open the IDX file in readable binary mode.\n",
    "filename = {'train_images' : './mnist_dataset/train-images.idx3-ubyte' ,'train_labels' : './mnist_dataset/train-labels.idx1-ubyte',\n",
    "            'test_img':'./mnist_dataset/t10k-images.idx3-ubyte','test_lbl':'./mnist_dataset/t10k-labels.idx1-ubyte'}\n",
    "train_imagesfile = open(filename['train_images'],'rb')\n",
    "train_labelsfile = open(filename['train_labels'],'rb')\n",
    "test_imagesfile = open(filename['test_img'],'rb')\n",
    "test_labelsfile = open(filename['test_lbl'],'rb')\n",
    "\n",
    "\n",
    "# Set pointer to the beginning of the file.\n",
    "train_imagesfile.seek(0)\n",
    "train_labelsfile.seek(0)\n",
    "test_imagesfile.seek(0)\n",
    "test_labelsfile.seek(0)\n",
    "\n",
    "# Read the magic number\n",
    "magic_img = st.unpack('>4B',train_imagesfile.read(4))\n",
    "magic_lab = st.unpack('>4B',train_labelsfile.read(4))\n",
    "magic_test_img = st.unpack('>4B',test_imagesfile.read(4))\n",
    "magic_test_lab = st.unpack('>4B',test_labelsfile.read(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the dimensions of the Image data-set\n",
    "train_images = st.unpack('>I',train_imagesfile.read(4))[0] #num of images\n",
    "n_row_i = st.unpack('>I',train_imagesfile.read(4))[0] #num of rows\n",
    "n_col_i = st.unpack('>I',train_imagesfile.read(4))[0] #num of column\n",
    "\n",
    "test_images = st.unpack('>I',test_imagesfile.read(4))[0] #num of images\n",
    "n_row_test = st.unpack('>I',test_imagesfile.read(4))[0] #num of rows\n",
    "n_col_test = st.unpack('>I',test_imagesfile.read(4))[0] #num of column\n",
    "\n",
    "# Read the dimensions of the Label data-set\n",
    "train_labels = st.unpack('>I',train_labelsfile.read(4))[0] #num of items\n",
    "test_labels = st.unpack('>I',test_labelsfile.read(4))[0] #num of items\n",
    "\n",
    "# Reading the Image data\n",
    "train_bytes_total = train_images*n_row_i*n_col_i*1 \n",
    "test_bytes_total = test_images*n_row_test*n_col_test*1 \n",
    "\n",
    "# 'B' is used since it is of 'unsigned char' C type and ‘integer’ Python type\n",
    "# and has standard size 1 as mentioned in the official documentation of struct.\n",
    "# ‘>’ is used since the data is in MSB first (high endian) format used by most \n",
    "# non-Intel processors, as mentioned in their original website.\n",
    "train_img = 255 - np.asarray(st.unpack('>'+'B'*train_bytes_total,train_imagesfile.read(train_bytes_total))).reshape((train_images,n_row_i,n_col_i))\n",
    "test_img =   255 - np.asarray(st.unpack('>'+'B'*test_bytes_total,test_imagesfile.read(test_bytes_total))).reshape((test_images,n_row_test,n_col_test))\n",
    " \n",
    "# Reading the label data\n",
    "train_lbl = np.asarray(st.unpack('>'+'B'*train_labels,train_labelsfile.read(train_labels))).reshape((train_labels))\n",
    "test_lbl = np.asarray(st.unpack('>'+'B'*test_labels,test_labelsfile.read(test_labels))).reshape((test_labels))\n",
    "print(train_img.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape to the expected CNN format \n",
    "train_img = train_img.reshape(train_img.shape[0], train_img.shape[1], train_img.shape[2], 1).astype('float32')\n",
    "test_img = test_img.reshape(test_img.shape[0], test_img.shape[1], test_img.shape[2], 1).astype('float32')\n",
    "\n",
    "print(test_img[132].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMCUlEQVR4nO3dQcgc9RnH8d+vai/qITZrCFEaKx4qhUZZQsFiEqQSc4keLOYgKQjxoKDgoWIPSW6hVKWHIsQaTItVBBVzkNYQXiNexFVSjQ1trKQa85JsyMF4stGnh3dSXuPuzrozO7N5n+8Hlt2d2dl5sry/zO48M/N3RAjA0ve9tgsA0AzCDiRB2IEkCDuQBGEHkri0yZUtX748Vq9e3eQqgVSOHTum06dPe9C8SmG3vVHS7yVdIumPEbFr1OtXr16tXq9XZZUARuh2u0PnTfw13vYlkv4g6Q5JN0raYvvGSd8PwHRV+c2+VtJHEfFxRHwp6QVJm+spC0DdqoR9laRPFz0/Xkz7BtvbbPds9/r9foXVAaiiStgH7QT41rG3EbE7IroR0e10OhVWB6CKKmE/LunaRc+vkXSiWjkApqVK2N+RdIPt62x/X9I9kvbVUxaAuk3ceouIc7YflPQ3LbTe9kTEh7VVBqBWlfrsEfGapNdqqgXAFHG4LJAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDpkM5aeN954Y+T8nTt3TrxsVXNzc0PnrV+/fqrrnkVs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCfrsyVXpk4+zfJtG1Zaxz14p7LaPSTor6StJ5yKiW0dRAOpXx5Z9Q0ScruF9AEwRv9mBJKqGPSS9bvtd29sGvcD2Nts9271+v19xdQAmVTXst0TEzZLukPSA7VsvfEFE7I6IbkR0O51OxdUBmFSlsEfEieL+lKRXJK2toygA9Zs47LYvt33l+ceSbpd0uK7CANSryt74FZJesX3+ff4SEX+tpapkynrVVXrZBw8enNp74+Iycdgj4mNJP62xFgBTROsNSIKwA0kQdiAJwg4kQdiBJDjFtQFl7a0NGzY0U8hFpuppqBlPYx2FLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEGfvQaZ++jbt28fOX9Ur5s+eLPYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEvTZa3Ax99Gr9MnHmY/ZwZYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Kgz16Dubm5kfOn3Ycf1SunT47zSrfstvfYPmX78KJpV9neb/tocb9sumUCqGqcr/HPStp4wbRHJR2IiBskHSieA5hhpWGPiDclnblg8mZJe4vHeyXdWXNdAGo26Q66FRExL0nF/dXDXmh7m+2e7V6/359wdQCqmvre+IjYHRHdiOh2Op1prw7AEJOG/aTtlZJU3J+qryQA0zBp2PdJ2lo83irp1XrKATAtpX12289LWi9pue3jkrZL2iXpRdv3SfpE0t3TLHLWVe1ll113vszBgwcnXjfyKA17RGwZMuu2mmsBMEUcLgskQdiBJAg7kARhB5Ig7EASnOLagLLLNVdtvY1avuy9y1pz69atq7Q8rb/ZwZYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JwRDS2sm63G71er7H1XSx27Ngxcv6oU1il6n36aeIy183qdrvq9XoeNI8tO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQZ99CRg1JPQs9+DLlF0HoOz4hIzoswMg7EAWhB1IgrADSRB2IAnCDiRB2IEk6LMvcWV99qp9+J07d1Zafprm5uaGzluq58pX6rPb3mP7lO3Di6btsP2Z7UPFbVOdBQOo3zhf45+VtHHA9CcjYk1xe63esgDUrTTsEfGmpDMN1AJgiqrsoHvQ9vvF1/xlw15ke5vtnu1ev9+vsDoAVUwa9qckXS9pjaR5SY8Pe2FE7I6IbkR0O53OhKsDUNVEYY+IkxHxVUR8LelpSWvrLQtA3SYKu+2Vi57eJenwsNcCmA2lfXbbz0taL2m5pJOSthfP10gKScck3R8R82Uro8+ez6yea79Uz5Uf1We/tGzhiNgyYPIzlasC0CgOlwWSIOxAEoQdSIKwA0kQdiCJ0r3xQBWjTjMta72VnT5bpXVX9t5LcThptuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kAR99hlQ1i++GHu64yj7d7V5mepRp+ZKUpOXYK8LW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSII+ewPKLktctZ886rLIbV8SedQxBNM8X72qpXhsA1t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCPvsSMKonXNarLjtvO6tR17u/WJVu2W1fa3vO9hHbH9p+qJh+le39to8W98umXy6ASY3zNf6cpEci4seSfibpAds3SnpU0oGIuEHSgeI5gBlVGvaImI+I94rHZyUdkbRK0mZJe4uX7ZV057SKBFDdd9pBZ3u1pJskvS1pRUTMSwv/IUi6esgy22z3bPf6/X61agFMbOyw275C0kuSHo6Iz8ddLiJ2R0Q3IrqdTmeSGgHUYKyw275MC0F/LiJeLiaftL2ymL9S0qnplAigDqWtN9uW9IykIxHxxKJZ+yRtlbSruH91KhWiFO2zwUa1JNetW9dcITNinD77LZLulfSB7UPFtMe0EPIXbd8n6RNJd0+nRAB1KA17RLwlyUNm31ZvOQCmhcNlgSQIO5AEYQeSIOxAEoQdSMJNDj3b7Xaj1+s1tr6lYuFQB1yo7DTUpXg56DLdble9Xm/gHwxbdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgktJXwTK+slVhjauOlx0WS97KV6S+WLFlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuB8dmAJ4Xx2AIQdyIKwA0kQdiAJwg4kQdiBJAg7kERp2G1fa3vO9hHbH9p+qJi+w/Zntg8Vt03TLxfApMa5eMU5SY9ExHu2r5T0ru39xbwnI+J30ysPQF3GGZ99XtJ88fis7SOSVk27MAD1+k6/2W2vlnSTpLeLSQ/aft/2HtvLhiyzzXbPdq/f71cqFsDkxg677SskvSTp4Yj4XNJTkq6XtEYLW/7HBy0XEbsjohsR3U6nU0PJACYxVthtX6aFoD8XES9LUkScjIivIuJrSU9LWju9MgFUNc7eeEt6RtKRiHhi0fSVi152l6TD9ZcHoC7j7I2/RdK9kj6wfaiY9pikLbbXSApJxyTdP5UKAdRinL3xb0kadH7sa/WXA2BaOIIOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRKNDNtvuS/rPoknLJZ1urIDvZlZrm9W6JGqbVJ21/TAiBl7/rdGwf2vldi8iuq0VMMKs1jardUnUNqmmauNrPJAEYQeSaDvsu1te/yizWtus1iVR26Qaqa3V3+wAmtP2lh1AQwg7kEQrYbe90fY/bX9k+9E2ahjG9jHbHxTDUPdarmWP7VO2Dy+adpXt/baPFvcDx9hrqbaZGMZ7xDDjrX52bQ9/3vhvdtuXSPqXpF9IOi7pHUlbIuIfjRYyhO1jkroR0foBGLZvlfSFpD9FxE+Kab+VdCYidhX/US6LiF/PSG07JH3R9jDexWhFKxcPMy7pTkm/Uouf3Yi6fqkGPrc2tuxrJX0UER9HxJeSXpC0uYU6Zl5EvCnpzAWTN0vaWzzeq4U/lsYNqW0mRMR8RLxXPD4r6fww461+diPqakQbYV8l6dNFz49rtsZ7D0mv237X9ra2ixlgRUTMSwt/PJKubrmeC5UO492kC4YZn5nPbpLhz6tqI+yDhpKapf7fLRFxs6Q7JD1QfF3FeMYaxrspA4YZnwmTDn9eVRthPy7p2kXPr5F0ooU6BoqIE8X9KUmvaPaGoj55fgTd4v5Uy/X83ywN4z1omHHNwGfX5vDnbYT9HUk32L7O9vcl3SNpXwt1fIvty4sdJ7J9uaTbNXtDUe+TtLV4vFXSqy3W8g2zMoz3sGHG1fJn1/rw5xHR+E3SJi3skf+3pN+0UcOQun4k6e/F7cO2a5P0vBa+1v1XC9+I7pP0A0kHJB0t7q+aodr+LOkDSe9rIVgrW6rt51r4afi+pEPFbVPbn92Iuhr53DhcFkiCI+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/AQxvGBGpPOXZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img[132].reshape(28, 28), cmap='gray')\n",
    "print(test_lbl[132])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode images_array & test_img\n",
    "train_img/=255\n",
    "test_img/=255\n",
    "\n",
    "# one hot encode\n",
    "train_lbl = kr.utils.to_categorical(train_lbl, 10)\n",
    "test_lbl = kr.utils.to_categorical(test_lbl, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 122s 2ms/sample - loss: 0.4191 - accuracy: 0.8899 - val_loss: 0.1501 - val_accuracy: 0.9557\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 118s 2ms/sample - loss: 0.1300 - accuracy: 0.9621 - val_loss: 0.0951 - val_accuracy: 0.9711\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 114s 2ms/sample - loss: 0.0878 - accuracy: 0.9746 - val_loss: 0.0788 - val_accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 114s 2ms/sample - loss: 0.0669 - accuracy: 0.9810 - val_loss: 0.0628 - val_accuracy: 0.9800\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.0547 - accuracy: 0.9839 - val_loss: 0.0561 - val_accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 123s 2ms/sample - loss: 0.0473 - accuracy: 0.9860 - val_loss: 0.0580 - val_accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 119s 2ms/sample - loss: 0.0392 - accuracy: 0.9883 - val_loss: 0.0505 - val_accuracy: 0.9834\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 120s 2ms/sample - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0501 - val_accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 123s 2ms/sample - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0476 - val_accuracy: 0.9849\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 116s 2ms/sample - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0455 - val_accuracy: 0.9851\n",
      "Metrics(Test loss & Test Accuracy): \n",
      "[0.04553688062198926, 0.9851]\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "# Convolution layer\n",
    "model.add(Conv2D(32,(3,3),input_shape = (train_img.shape[1],train_img.shape[2],1),activation = 'relu'))\n",
    "# Pooling as reducing feature map\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "# Full connection\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "\n",
    "# Compiling of the Model\n",
    "model.compile( optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit(train_img, train_lbl, validation_data=(test_img, test_lbl), epochs=10, batch_size=200)\n",
    "\n",
    "# Evaluation of the model\n",
    "metrics = model.evaluate(test_img, test_lbl, verbose=0)\n",
    "print(\"Metrics(Test loss & Test Accuracy): \")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "[2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prd_img = load_model.predict_classes(test_img[147].reshape(-1,28,28,1))\n",
    "\n",
    "plt.imshow(test_img[147].reshape(28, 28), cmap='gray')\n",
    "print(test_img[147].reshape(-1,28,28,1).shape)\n",
    "print(prd_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
